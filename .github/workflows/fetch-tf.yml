name: Fetch TorrentFreak

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */4 * * *'

jobs:
  parse:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          ref: gh-pages

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 unidecode

      - name: Parse HTML
        uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import requests
            from bs4 import BeautifulSoup
            from datetime import datetime, timedelta
            import json
            from unidecode import unidecode

            def parse_date(date_str):
                now = datetime.now()
                if 'today' in date_str.lower():
                    return now
                elif 'yesterday' in date_str.lower():
                    return now - timedelta(days=1)
                else:
                    try:
                        return datetime.strptime(date_str, '%B %d, %Y, %H:%M')
                    except ValueError:
                        return None

            base_url = 'https://torrentfreak.com/category/piracy'
            base_url2 = 'https://torrentfreak.com/category/anti-piracy'
            pages = [base_url, base_url2] + [f'{base_url}/page/{i}' for i in range(2, 6)] + [f'{base_url2}/page/{i}' for i in range(2, 6)]

            articles = []

            for page_url in pages:
                response = requests.get(page_url)
                soup = BeautifulSoup(response.text, 'html.parser')

                for article in soup.find_all('div', class_='col-4_sm-6_xs-12'):
                    link = article.find('a')['href']
                    img = article.find('img')['src']
                    title = article.find('h3', class_='preview-article__title').text
                    title = unidecode(title)
                    date_str = article.find('time').text.strip()
                    date = parse_date(date_str)
                    published_at = date.isoformat() if date else None

                    article_data = {
                        "source": {
                            "id": None,
                            "name": "TorrentFreak"
                        },
                        "title": title,
                        "url": link,
                        "urlToImage": img,
                        "publishedAt": published_at
                    }
                    articles.append(article_data)

            if articles:
                with open('tf.json', 'w') as f:
                    json.dump(articles, f)

      - name: Commit JSON file to gh-pages
        uses: EndBug/add-and-commit@v9
        with:
          author_name: GitHub Actions
          author_email: actions@github.com
          message: 'update tf'
          add: 'tf.json'
          branch: 'gh-pages'
